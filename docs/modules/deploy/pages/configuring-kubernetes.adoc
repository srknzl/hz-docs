= Configuring Kubernetes
:description: Before you start a Hazelcast cluster in Kubernetes, it's important to configure settings to ensure that members can form a cluster and to prevent any unexpected data loss.

{description}

== Discovering Members

To make it easier to set up clusters in Kubernetes, Hazelcast allows members to discover each other automatically, using discovery modes. Configure your members with one of the following discovery modes to allow them to form a cluster:

[cols="1a,1a,1a"]
|===
| | Kubernetes API  | DNS Lookup

|*Description*    | Uses REST calls to Kubernetes master to fetch IP addresses of Pods | Uses DNS to resolve IPs of Pods related to the given service

| *Pros*           | Flexible, supports **3 different options**:

- Hazelcast cluster per service
- Hazelcast cluster per multiple services (distinguished by labels)
- Hazelcast cluster per namespace | **No additional configuration** required, resolving DNS does not require granting any permissions

| *Cons*           | Requires setting up **RoleBinding** (to allow access to Kubernetes API)  | Limited to **headless Cluster IP** service

Limited to **Hazelcast cluster per service**  |
|===

=== Using Kubernetes in API Mode

In **Kubernetes API** mode, each node makes a REST call to the Kubernetes master to discover the IP addresses of any Hazelcast members running in Pods.

==== Granting Permissions to use Kubernetes API

To use the Kubernetes API, you must grant certain permissions.

To grant them for 'default' service account in 'default' namespace, execute the following command.

[source,shell]
----
kubectl apply -f https://raw.githubusercontent.com/hazelcast/hazelcast/master/kubernetes-rbac.yaml
----

==== Creating a Service

Hazelcast Kubernetes Discovery requires creating a link:https://kubernetes.io/docs/concepts/services-networking/service/[service] of any type in any Pods where Hazelcast is running.

```yaml
apiVersion: v1
kind: Service
metadata:
  name: MY-SERVICE-NAME
spec:
  type: LoadBalancer
  selector:
    app: APP-NAME
  ports:
  - name: hazelcast
    port: 5701
```

==== Hazelcast Configuration

The second step is to configure the discovery plugin inside `hazelcast.yaml` or an equivalent Java-based configuration.

[tabs] 
==== 
YAML:: 
+ 
-- 
```yaml
hazelcast:
  network:
    join:
      multicast:
        enabled: false
      kubernetes:
        enabled: true
        namespace: MY-KUBERNETES-NAMESPACE
        service-name: MY-SERVICE-NAME
```
--
Java:: 
+ 
-- 
```java
config.getNetworkConfig().getJoin().getMulticastConfig().setEnabled(false);
config.getNetworkConfig().getJoin().getKubernetesConfig().setEnabled(true)
      .setProperty("namespace", "MY-KUBERNETES-NAMESPACE")
      .setProperty("service-name", "MY-SERVICE-NAME");
```
--
====

There are several properties to configure, all of which are optional.

* `namespace`: Kubernetes Namespace where Hazelcast is running; if not specified, the value is taken from the environment variables `KUBERNETES_NAMESPACE` or `OPENSHIFT_BUILD_NAMESPACE`. If those are not set, the namespace of the Pod will be used (retrieved from `/var/run/secrets/kubernetes.io/serviceaccount/namespace`).
* `service-name`: service name used to scan only Pods connected to the given service; if not specified, then all Pods in the namespace are checked
* `service-label-name`, `service-label-value`: service label and value used to tag services that should form the Hazelcast cluster together
* `pod-label-name`, `pod-label-value`: pod label and value used to tag pods that should form the Hazelcast cluster together
* `resolve-not-ready-addresses`: if set to `true`, it checks also the addresses of Pods which are not ready; `true` by default
* `use-node-name-as-external-address`: if set to `true`, uses the node name to connect to a `NodePort` service instead of looking up the external IP using the API; `false` by default
* `kubernetes-api-retries`: number of retries in case of issues while connecting to Kubernetes API; defaults to `3` 
* `kubernetes-master`: URL of Kubernetes Master; `https://kubernetes.default.svc` by default
* `api-token`: API Token to Kubernetes API; if not specified, the value is taken from the file `/var/run/secrets/kubernetes.io/serviceaccount/token`
* `ca-certificate`: CA Certificate for Kubernetes API; if not specified, the value is taken from the file `/var/run/secrets/kubernetes.io/serviceaccount/ca.crt`
* `service-port`: endpoint port of the service; if specified with a value greater than `0`, it overrides the default; `0` by default
 
You can use one of `service-name`,`service-label`(`service-label-name`, `service-label-value`) and `pod-label`(`pod-label-name`, `pod-label-value`) based discovery mechanisms, configuring two of them at once does not make sense.

NOTE: If you don't specify any property at all, then the Hazelcast cluster is formed using all Pods in your current namespace. In other words, you can look at the properties as a grouping feature if you want to have multiple Hazelcast clusters in one namespace.

=== Using Kubernetes in DNS Lookup Mode

**DNS Lookup** mode uses a feature of Kubernetes that **headless** (without cluster IP) services are assigned a DNS record which resolves to the set of IPs of related Pods.

==== Creating Headless Service

Headless service is a service of type `ClusterIP` with the `clusterIP` property set to `None`.

```yaml
apiVersion: v1
kind: Service
metadata:
  name: MY-SERVICE-NAME
spec:
  type: ClusterIP
  clusterIP: None
  selector:
    app: APP-NAME
  ports:
  - name: hazelcast
    port: 5701
```

==== Hazelcast Configuration

The Hazelcast configuration to use DNS Lookup looks as follows.

[tabs] 
==== 
YAML:: 
+ 
-- 
```yaml
hazelcast:
  network:
    join:
      multicast:
        enabled: false
      kubernetes:
        enabled: true
        service-dns: MY-SERVICE-DNS-NAME
```
-- 
Java:: 
+ 
-- 
```java
config.getNetworkConfig().getJoin().getMulticastConfig().setEnabled(false);
config.getNetworkConfig().getJoin().getKubernetesConfig().setEnabled(true)
      .setProperty("service-dns", "MY-SERVICE-DNS-NAME");
```
--
====

There are 3 properties to configure the plugin:

* `service-dns` (required): service DNS, usually in the form of `SERVICE-NAME.NAMESPACE.svc.cluster.local`
* `service-dns-timeout` (optional): custom time for how long the DNS Lookup is checked
* `service-port` (optional): the Hazelcast port; if specified with a value greater than 0, it overrides the default (default port = `5701`)

== Partitioning to Prevent Data Loss

By default, Hazelcast distributes partition replicas (backups) randomly and equally among cluster members. However, this is not safe in terms of high availability when a partition and its replicas are stored on the same rack, using the same network, or power source. To deal with that, Hazelcast offers logical partition grouping, so that a partition
itself and its backups would not be stored within the same group. This way Hazelcast guarantees that a possible failure
affecting more than one member at a time will not cause data loss. For more details about partition groups, see xref:clusters:partition-group-configuration.adoc[Partition Group Configuration].

=== Zone Aware

When using `ZONE_AWARE` configuration, backups are created in the other availability zone. This feature is available only for the Kubernetes API mode.

NOTE: Your Kubernetes cluster must orchestrate Hazelcast Member Pods equally between the availability zones, otherwise Zone Aware feature may not work correctly.

[tabs] 
==== 
YAML:: 
+ 
-- 
```yaml
partition-group:
  enabled: true
  group-type: ZONE_AWARE
```
--
Java:: 
+ 
-- 
```java
config.getPartitionGroupConfig()
    .setEnabled(true)
    .setGroupType(MemberGroupType.ZONE_AWARE);
```
--
====

Note the following aspects of `ZONE_AWARE`:

* Kubernetes cluster must provide the link:https://kubernetes.io/docs/reference/kubernetes-api/labels-annotations-taints/#failure-domainbetakubernetesiozone[well-known Kubernetes annotations]
* Retrieving Zone Name uses Kubernetes API, so <<granting-permissions-to-use-kubernetes-api, RBAC must be configured>>
* `ZONE_AWARE` feature works correctly when Hazelcast members are distributed equally in all zones, so your Kubernetes cluster must orchestrate Pods equally
 
Note also that retrieving Zone Name assumes that your container's hostname is the same as Pod Name, which is almost always true. If you happen to change your hostname in the container, then please define the following environment variable:
 
```yaml
env:
  - name: POD_NAME
    valueFrom:
      fieldRef:
        fieldPath: metadata.name
``` 

=== Node Aware

When using `NODE_AWARE` configuration, backups are created in the other Kubernetes nodes. This feature is available only for the Kubernetes API mode.

NOTE: Your Kubernetes cluster must orchestrate Hazelcast Member Pods equally between the nodes, otherwise Node Aware feature may not work correctly.

==== YAML Configuration

```yaml
partition-group:
  enabled: true
  group-type: NODE_AWARE
```

==== Java-based Configuration

```java
config.getPartitionGroupConfig()
    .setEnabled(true)
    .setGroupType(MemberGroupType.NODE_AWARE);
```

Note the following aspects of `NODE_AWARE`:

* Retrieving name of the node uses Kubernetes API, so <<granting-permissions-to-use-kubernetes-api, RBAC must be configured>>
* `NODE_AWARE` feature works correctly when Hazelcast members are distributed equally in all nodes, so your Kubernetes cluster must orchestrate Pods equally.
 
Note also that retrieving name of the node assumes that your container's hostname is the same as Pod Name, which is almost always true. If you happen to change your hostname in the container, then please define the following environment variable:
 
```yaml
env:
- name: POD_NAME
  valueFrom:
    fieldRef:
      fieldPath: metadata.name
```

== Preventing Data Loss During Upgrades

By default, Hazelcast does not shutdown gracefully. As a result, if you suddenly terminate more members than your configured `backup-count` property (1 by default), you may lose the cluster data.

To prevent data loss, set the following properties.

NOTE: All these properties are already set in xref:deploying-in-kubernetes.adoc#helm-chart[Hazelcast Helm Charts].

- `terminationGracePeriodSeconds`:  in your StatefulSet (or Deployment) configuration; the value should be high enough to cover the data migration process
- `-Dhazelcast.shutdownhook.policy=GRACEFUL`: in the JVM parameters
- `-Dhazelcast.graceful.shutdown.max.wait`: in the JVM parameters; the value should be high enough to cover the data migration process
- If you use Deployment (not StatefulSet), you need to set your strategy to link:https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#updating-a-deployment[RollingUpdate] and ensure Pods are updated one by one.
- If you upgrade by the minor version, e.g., `3.11.4 => 3.12` (Enterprise feature), you need to set the `-Dhazelcast.cluster.version.auto.upgrade.enabled=true` JVM property to make sure the cluster version updates automatically.

== Discovering Members from Hazelcast Clients

Depending on whether your Hazelcast client runs inside or outside the Kubernetes cluster, its configuration looks different.

=== Inside Kubernetes Cluster

If you have a Hazelcast cluster deployed on Kubernetes and you want to configure Hazelcast Client deployed on the same Kubernetes cluster, then the configuration looks very similar to Hazelcast Member.

Here's an example in case of the **Kubernetes API** mode.

[tabs] 
==== 
YAML:: 
+ 
-- 
```yaml
hazelcast-client:
  network:
    kubernetes:
      enabled: true
      namespace: MY-KUBERNETES-NAMESPACE
      service-name: MY-SERVICE-NAME
```
--
Java:: 
+ 
-- 
```java
clientConfig.getNetworkConfig().getKubernetesConfig().setEnabled(true)
            .setProperty("namespace", "MY-KUBERNETES-NAMESPACE")
            .setProperty("service-name", "MY-SERVICE-NAME");
```
--
====

=== Outside Kubernetes Cluster

If your Hazelcast cluster is deployed on Kubernetes, but Hazelcast Client is in a completely different network, then they can connect only through the public Internet network. This requires a special configuration of both Hazelcast server and Hazelcast client. You can find a complete guide on how to set it up here: link:https://hazelcast.com/blog/how-to-set-up-your-own-on-premises-hazelcast-on-kubernetes/[How to Set Up Your Own On-Premises Hazelcast on Kubernetes].

To use **Hazelcast Dummy Client** (`<smart-routing>false</smart-routing>`) you don't need any plugin, it's enough to expose your Hazelcast cluster with a LoadBalancer (or NodePort) service and set its IP/port as the TCP/IP Hazelcast Client configuration. Dummy Client, however, compromises the performance, since all the communication happens against a single Hazelcast member.

To configure **Hazelcast Smart Client**, you need to perform the following steps:

* Expose each Hazelcast Member Pod with a separate LoadBalancer or NodePort service (the simplest way to do it is to install link:https://metacontroller.app/[Metacontroller] and link:https://github.com/GoogleCloudPlatform/metacontroller/tree/master/examples/service-per-pod[service-per-pod] Decorator Controller)
* Configure ServiceAccount with ClusterRole having at least `get` and `list` permissions to the following resources: `endpoints`, `pods`, `nodes`, `services`
* Use credentials from the created ServiceAccount in the Hazelcast Client configuration (credentials can be fetched with `kubectl get secret <sevice-account-secret> -o jsonpath={.data.token} | base64 --decode` and `kubectl get secret <sevice-account-secret> -o jsonpath={.data.ca\\.crt} | base64 --decode`)

```yaml
hazelcast-client:
  network:
    kubernetes:
      enabled: true
      namespace: MY-KUBERNETES-NAMESPACE
      service-name: MY-SERVICE-NAME
      use-public-ip: true
      kubernetes-master: https://35.226.182.228
      api-token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJkZWZhdWx0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZWNyZXQubmFtZSI6InNhbXBsZS1zZXJ2aWNlLWFjY291bnQtdG9rZW4tNnM5NGgiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoic2FtcGxlLXNlcnZpY2UtYWNjb3VudCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjI5OTI1NzBmLTI1NDQtMTFlOS1iNjg3LTQyMDEwYTgwMDI4YiIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDpkZWZhdWx0OnNhbXBsZS1zZXJ2aWNlLWFjY291bnQifQ.o-j4e-ducrMmQc23xYDnPr6TIyzlAs3pLNAmGLqPe9Vq1mwsxOh3ujcVKR90HAdkfHIF_Sw66qC9hXIDvxfqN_rLXlOKbvTX3gjDrAnyY_93Y3MpmSBj8yR9yHMb4O29a9UIwN5F2_VoCsc0IGumScU_EhPYc9mvEXlwp2bATQOEU-SVAGYPqvVPs9h5wjWZ7WUQa_-RBLMF6KRc9EP2i3c7dPSRVL9ZQ6k6OyUUOVEaPa1tqIxP7vOgx9Tg2C1KmYF5RDrlzrWkhEcjd4BLTiYDKEyaoBff9RqdPYlPwu0YcEH-F7yU8tTDN74KX5jvah3amg_zTiXeNoe5ZFcVdg
      ca-certificate: |
        -----BEGIN CERTIFICATE-----
        MIIDCzCCAfOgAwIBAgIQVcTHv3jK6g1l7Ph9Xyd9DTANBgkqhkiG9w0BAQsFADAv
        MS0wKwYDVQQDEyQ4YjRhNjgwMS04NzJhLTQ2NDEtYjIwOC0zYjEyNDEwYWVkMTcw
        HhcNMTkwMTMxMDcyNDMxWhcNMjQwMTMwMDgyNDMxWjAvMS0wKwYDVQQDEyQ4YjRh
        NjgwMS04NzJhLTQ2NDEtYjIwOC0zYjEyNDEwYWVkMTcwggEiMA0GCSqGSIb3DQEB
        AQUAA4IBDwAwggEKAoIBAQCaty8l9aHeWE1r9yLWKJMa3YQotVclYoEHegB8y6Ke
        +zKqa06JKKrz3Qony97VdWR/NMpRYXouSF0owDv9BIoLTC682wlQtNB1c4pTVW7a
        AikoNtyNIT8gtA5w0MyjFrbNslUblXvuo0HIeSmJREUmT7BC3VaKgkg64mVdf0DJ
        NyrcL+qyCs1m03mi12hgzI72O3qgEtP91tu/oCUdOh39u13TB0fj5tgWURMFgkxo
        T0xiNfPueV3pe8uYxBntzFn/74ibiizLRP6d/hsuRdS7IA+bvRLKG/paYwyZuMFb
        BDA+kXXAIkOvCpIQCkAKMpyyDz9lBVCtl3eRSAJQLBefAgMBAAGjIzAhMA4GA1Ud
        DwEB/wQEAwICBDAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQBP
        TBRY1IbkFJuboMKLW9tdpIzW7hf2qsTLOhtlaJbMXrWaXCTrl8qUgBUZ1sWAW9Uk
        qETwRoCMl1Ht7PhbnXEGDNt3Sw3Y3feR4PsffhcgWH0BK8pZVY0Q1zbZ6dVNbU82
        EUrrcnV0uiB/JFsJ3rg8qJurutro3uIzAhb9ixYRqYnXUR4q0bxahO04iSUHvtYQ
        JmWp1GCb/ny9MyeTkwh2Q+WIQBHsX4LfrKjPwJd6qZME7BmwryYBTkGa0FinmhRg
        SdSPEQKmuXmghPU5GLudiI2ooOaqOXIjVPfM/cw4uU9FCGM49qufccOOt6utk0SM
        DwupAKLLiaYs47a8JgUa
        -----END CERTIFICATE-----
```

NOTE: Hazelcast Client outside Kubernetes cluster works only in the **Kubernetes API** mode (it does not work in the **DNS Lookup** mode).

NOTE: If you use Minikube, you need to execute `minikube tunnel` in order to get LoadBalancer External IPs assigned.